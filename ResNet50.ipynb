{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10250748,"sourceType":"datasetVersion","datasetId":6340370}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fall Detection using ResNet50 with Data Augmentation and F1 Thresholding","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomRotation, ColorJitter\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom PIL import Image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 1: Configuration ---------------- #\nTRAIN_DIR = \"/kaggle/input/dataslayer2/train\"\nTEST_DIR = \"/kaggle/input/dataslayer2/test\"\nSUBMISSION_FILE = \"submission.csv\"\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nEPOCHS = 20\nLEARNING_RATE = 2e-5\nRANDOM_STATE = 42","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 2: Data Preparation ---------------- #\ndef preprocess_dataset(directory):\n    images, labels = [], []\n    for subject in os.listdir(directory):\n        subject_path = os.path.join(directory, subject)\n        if not os.path.isdir(subject_path):\n            continue\n        for category in [\"fall\", \"non_fall\"]:\n            category_path = os.path.join(subject_path, category)\n            label = 1 if category == \"fall\" else 0\n            if os.path.isdir(category_path):\n                for root, _, files in os.walk(category_path):\n                    for file in files:\n                        if file.endswith((\".jpg\", \".png\", \".jpeg\")):\n                            img_path = os.path.join(root, file)\n                            images.append(img_path)\n                            labels.append(label)\n    return images, labels\n\nX, y = preprocess_dataset(TRAIN_DIR)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\nprint(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 3: Dataset Definition ---------------- #\ntrain_transform = Compose([\n    Resize(IMG_SIZE),\n    RandomHorizontalFlip(),\n    RandomRotation(10),\n    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ToTensor(),\n    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\nval_transform = Compose([\n    Resize(IMG_SIZE),\n    ToTensor(),\n    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels=None, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        image = self.transform(image) if self.transform else image\n        data = {\"image\": image}\n        if self.labels is not None:\n            data[\"label\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return data\n\ntrain_dataset = ImageDataset(X_train, y_train, transform=train_transform)\nval_dataset = ImageDataset(X_val, y_val, transform=val_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 4: Model Definition ---------------- #\nclass CNN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(CNN, self).__init__()\n        self.model = models.resnet50(pretrained=True)\n        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.model(x)\n\nmodel = CNN(num_classes=2).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 5: Training Loop ---------------- #\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n    train_losses, val_losses, val_f1_scores = [], [], []\n    best_f1 = 0\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for batch in tqdm(train_loader):\n            images = batch[\"image\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        train_loss = running_loss / len(train_loader)\n        train_losses.append(train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss, val_preds, val_labels = 0.0, [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                images = batch[\"image\"].to(device)\n                labels = batch[\"label\"].to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n        val_loss /= len(val_loader)\n        val_losses.append(val_loss)\n        val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n        val_f1_scores.append(val_f1)\n\n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(f\"Saved Best Model with F1: {best_f1:.4f}\")\n\n    return train_losses, val_losses, val_f1_scores\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrain_losses, val_losses, val_f1_scores = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 6: Learning Curve ---------------- #\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 7: Validation Metrics ---------------- #\nbest_model = CNN(num_classes=2)\nbest_model.load_state_dict(torch.load(\"best_model.pth\"))\nbest_model = best_model.to(device)\nbest_model.eval()\n\nval_preds, val_labels, val_probs = [], [], []\nwith torch.no_grad():\n    for batch in val_loader:\n        images = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n        outputs = best_model(images)\n        probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n        val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n        val_probs.extend(probs)\n        val_labels.extend(labels.cpu().numpy())\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(val_labels, val_preds, target_names=[\"non_fall\", \"fall\"]))\n\nconf_matrix = confusion_matrix(val_labels, val_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"non_fall\", \"fall\"], yticklabels=[\"non_fall\", \"fall\"])\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- STEP 8: Test Predictions with Threshold Optimization ---------------- #\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels=None, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        except Exception as e:\n            print(f\"Error loading image: {self.image_paths[idx]}, {e}\")\n            image = Image.new(\"RGB\", IMG_SIZE)  # Use a blank image as a fallback\n\n        image = self.transform(image) if self.transform else image\n        data = {\"image\": image, \"path\": self.image_paths[idx]}  # Store path for later use\n        if self.labels is not None:\n            data[\"label\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return data\n\ntest_images = [os.path.join(TEST_DIR, img) for img in os.listdir(TEST_DIR) if img.endswith((\".jpg\", \".png\", \".jpeg\"))]\ntest_dataset = ImageDataset(test_images, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\ntest_probs, test_ids = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[\"image\"].to(device)\n        outputs = best_model(images)\n        probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Probability for 'fall'\n        test_probs.extend(probs)\n        test_ids.extend([os.path.basename(path) for path in batch[\"path\"]])  # Access paths from dataset\n\n# Find optimal threshold using validation probabilities\nif len(val_probs) > 0:  # Ensure val_probs is not empty\n    best_threshold, best_f1 = 0, 0\n    thresholds = np.linspace(0.1, 0.9, 50)\n    for threshold in thresholds:\n        val_preds_threshold = (np.array(val_probs) > threshold).astype(int)\n        f1 = f1_score(val_labels, val_preds_threshold)\n        if f1 > best_f1:\n            best_f1, best_threshold = f1, threshold\n\n    print(f\"Best Threshold: {best_threshold:.2f}, Best F1 Score: {best_f1:.4f}\")\n\n    # Apply best threshold to test data\n    test_preds = (np.array(test_probs) > best_threshold).astype(int)\n\n    submission = pd.DataFrame({\"id\": test_ids, \"label\": test_preds})\n    submission.to_csv(SUBMISSION_FILE, index=False)\n    print(f\"Submission saved with threshold {best_threshold:.2f}\")\nelse:\n    print(\"Validation probabilities are empty. Skipping threshold optimization.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}